# Synergy:超越 GPU 在多租户集群上进行 DNN 调度

**[Synergy:Looking Beyond GPUs for DNN Scheduling on Multi-Tenant Clusters](usenix.org/conference/osdi22/presentation/mohan)**  

解决的主要问题：

虽然说GPU是现在DNN训练的主要资源，但是CPU和内存的分配也会影响训练性能。本文主要研究针对不同的负载，使用不同CPU和内存的组合来提高训练速度。

Synergy 的工作原理是提高因数据停滞而成为瓶颈的作业的吞吐量。

优点：

既可以节约CPU和内存的资源【需要的资源更少】，又可以提高训练速度【增加配置的资源】。

既有利于服务提供商，也有利于用户。

## 论文作者：

* Jayashree Mohan：德克萨斯大学奥斯汀分校，方向：操作系统、存储、网络。
* Amar Phanishayee：微软研究人员，研究目标是为大规模数据密集型计算创建高性能和高效的系统。
* Janardhan Kulkarni：微软研究人员。
* Vijay Chidambaram：副教授，计算机科学系，德克萨斯大学奥斯汀分校。

## 研究动机：

* 现有的 DNN 调度器通常假设 **GPU 是调度任务中占据主导地位的资源（dominant resources）**，只要 GPU 需求能够被满足，训练任务就可以被启动。CPU 和内存等其他资源，只需要按照 GPU 的占用比例进行分配即可。
  $$
  Allocated\_CPU = \frac{Total\_CPU}{Total\_GPU} * Allocated\_GPU \\
  Allocated\_MEM = \frac{Total\_MEM}{Total\_GPU} * Allocated\_GPU
  $$

* 作者发现：**DNN 对分配给作业的 CPU 和内存等辅助资源的数量表现出不同的敏感性**。比如说：对于一些图像和视频识别模型，当分配的 CPU 超过其 GPU 比例份额时，实现高达 3 倍的加速；但是对于大多数语言模型【比如：GNMT】，他们对 CPU 分配不敏感，当分配的 CPU 少于 GPU 时，其训练速度也不会有明显的下降。

  <img src="https://s3.bmp.ovh/imgs/2022/11/04/ef8d93fe548c1608.png" alt="image-20221104161429887" style="zoom:50%;" />

* 基于上述观测，作者提出了面向 **同构的** 、多租户集群的调度器 Synergy，它能够很好地识别不同的 DNN 对 CPU 和 MEM 的敏感度，并给出精细化的分配方案。 具体地，Synergy 包含如下两个组成部分：

  * **最优化分析**（**Optimistic Profiling**）：Synergy 测试并分析了在不同数量的 CPU 和 MEM 的组合下 DNN 训练任务的吞吐量。这个过程并非简单的枚举，而是使用了一些 trick 来降低计算量。分析结果对 CPU 和 MEM 的最优分配起到了重要作用。
  * **调度机制**（**Scheduling mechanism**）：Synergy 识别一组可以调度的任务，并根据分析的到的资源配置为每个任务设置合适的CPU和MEM资源。



## 系统架构

### 系统总览

<img src="https://s3.bmp.ovh/imgs/2022/11/04/5216a9688b589b8d.png" alt="image-20221104170717966" style="zoom:50%;" />



### Optimistic Profiling

#### 理论

对于每一种提交的作业，Synergy 构造了一个 **资源敏感性矩阵（resource sensitivity matrix）**。如图 4 所示，这个矩阵试图记录不同的资源组合下的 DNN 训练任务的吞吐量。显然，如果要遍历每一种可能的组合并测试当前组合下的吞吐量是不现实的。为此，作者提出了一种基于 [MinIO](https://github.com/minio/minio) 的评估方案。MinIO 作为一种应用级别的缓存， **可以保证一个 DNN 训练任务在每个 epoch 中拥有相同的缓存命中率** ， 这意味着，对于给定的 CPU 数量和存储带宽，我们可以建立吞吐量关于 MEM 数量的解析模型。因此，对于每一个 DNN，我们只需要将 MEM 固定为最大值，然后测试不同的 CPU 对吞吐量的影响即可（其他 MEM 数值下的吞吐量根据模型预测得到）。图 4 中的 empirical 和 estimated 正反应了这一点。

<img src="https://s3.bmp.ovh/imgs/2022/11/04/78209d79f5588313.png" alt="image-20221104170941040" style="zoom:50%;" />



为了进一步优化profiler的时间。作者采用了一种基于 **二分搜索** 的测试方案——如果当前测试点的吞吐量增长少于某个阈值（例如 10%），则在 CPU 数量较少的这半区继续二分搜索；否则在 CPU 数量较多的这半区进行。

填充完之后的资源敏感矩阵：

<img src="https://s3.bmp.ovh/imgs/2022/11/04/289e0ff4c971cc2a.png" alt="image-20221104171107997" style="zoom: 33%;" />

颜色越深表示训练吞吐量越大。要找到理想的资源分配，找到达到最大性能的最少资源 (CPU+mem)【图上的是：12CPU，75%内存】

#### 实验：

作者进行了一个实验来**验证Optimistic Profiling的准确性**：

<img src="https://s3.bmp.ovh/imgs/2022/11/04/eb3dad90ba7b2eed.png" alt="image-20221104172713470" style="zoom:50%;" />

左图中的 empirical 是 1-GPU ResNet18 的每秒处理的样本数，而 estimated 则是资源敏感性矩阵给出的结果。左图固定CPU数量，右图固定内存为最大内存。

该实验表明针对 MEM 的预测模型和针对 CPU 的二分搜索可以很好地模拟实际情况。





### Scheduling mechanism

在每一个调度周期内，Synergy 首先从队列中获取可以被调度的任务，然后为每一个任务创建一个需求向量（demand vector）。该向量包含了当前任务的 GPU 需求量，以及满足吞吐量需求的最小数量的 CPU 和 MEM 数值。根据这些需求向量将任务们分发到满足需求的节点上，这是一个 **多维的装箱问题（multi-dimensional bin packing problem）。** 



### Synergy-GREEDY: Greedy Scheduling

贪心策略：给定一个作业需求向量，贪心算法根据调度策略【FIFO, SRTF, LAS, or FTF】选择下一个可运行的作业，并将其放置在能够满足作业各个维度需求的服务器上。如果不存在这样的服务器，则跳过此轮的作业并检查下一个可运行作业的可调度性。

贪心策略出现的问题：

* 它可能导致辅助资源被作业耗尽，同时导致 GPU 未得到充分利用和碎片化。
* 它还损害了调度策略的公平性，因为如果集群中无法满足其资源需求，则可能会长时间跳过某些作业。



## Scheduling Algorithms

### Synergy-OPT

前提假设： **每个节点是同构的，具有相同的 GPU、CPU 和 MEM 装配量。** 

* 首先，我们假设一个理想化的设置：所有机器上可用的所有 CPU 和内存都存在于一台（超级）机器中。
* 之后将问题转化为一个线性规划问题。这个线性规划可以通过专业的求解器（例如 [CPLEX](https://www.ibm.com/analytics/cplex-optimizer) 或者 [CVXOPT](https://cvxopt.org/)）求解。
* 从而可以求出每一个任务的最优解，也就是每一个任务的最合适的CPU和MEM分配，但是以上的分析是建立在 **我们只有一个节点** 的假设上的。
* 需要增加一个线性规划问题来解决任务放置在哪个节点上。

算法的缺点：

* 求解这两个规划问题过于耗时；
* 第二个 LP 的求解会导致任务在单个节点上分配到非整数的 GPU 个数，例如 3.3 个 GPU。考虑到当前 GPU sharing 技术不是很成熟，我们不得不采用 rounding 的策略将其转化为整数解（例如，3.3→3），这就必然会带来性能损失。



### Synergy-TUNE

分配要求：

* 只请求单个 GPU 的任务，我们必须将其分发至单个节点（不对任务做切分）；
* 请求多个 GPU 的任务，可以被分发至单个节点，也可以被分发至多个节点（不同节点上启动的该任务的进程需要定期做 local gradients synchronization）。如果该任务被分发至多个节点，那么每个节点上 CPU 和 MEM 的分配遵循 GPU-proportional allocation 规则。 这样可以保证每个节点上的进程之间的进度不会差距过大，否则同步操作的耗时会增加。例如，如果一项作业需要（2GPU、12 CPU、300GB DRAM），那么在将其拆分到两台服务器时，我们需要确保每台服务器都能获得（1GPU、6CPU、150GB DRAM）。

算法：

* 在每个调度周期内，Synergy-TUNE 根据调度策略，选择一组GPU请求可以被满足的任务。然后按照 “先 GPU、后 CPU、最后 MEM” 的顺序对这些任务从大到小排序。接下来，从这个排好序的队伍中，Synergy-TUNE 依次取出每一个任务，计算其最优的 CPU 和 MEM 请求量，然后 **在遵循上述两个规则的前提下** 执行如下操作：

* **步骤 1：** 如果这是一个 single-GPU 任务，Synergy-TUNE 将为其选择一个「满足其 GPU 需求的、资源余量 **最少** 的」节点；

* **步骤 2：** 如果不存在单个节点能够满足其 GPU 请求，则尝试寻找 **最少的** 一组节点，使得该任务三个维度的资源需求都能够满足。

* **步骤 3**：

  如果整个集群的可用资源都不能满足这个任务，则执行如下操作：

  - **步骤 3.1：** 如果当前任务的 CPU 和 MEM 请求量大于 GPU-proportional allocation 的结果，则将其 CPU 和 MEM 请求量置为 GPU-proportional allocation，然后依次重试步骤 1 和步骤 2；否则进入步骤 3.2；
  - **步骤 3.2：** 如果一个任务无法被集群满足，或者其 CPU 和 MEM 请求量 **小于等于** GPU-proportional allocation 的结果，则执行如下操作：找到一个满足其 GPU 请求的节点，然后将该节点上正在运行的任务们依次切换到 GPU-proportional allocation 模式（从而释放出一定的 CPU 和 MEM 资源），直到当前任务的 CPU 和 MEM 请求可以被满足为止。

通过执行以上操作，Synergy-TUNE 至少可以保证其性能不亚于 GPU-proportional allocation。

<img src="https://s3.bmp.ovh/imgs/2022/11/04/bdfe8c9cbc5559d8.png" alt="image-20221104205904500" style="zoom:50%;" />





## 实验评估

### 实验环境：

测试的8个模型【负载】：

<img src="https://s3.bmp.ovh/imgs/2022/11/04/700df135df2cee32.png" alt="image-20221104210127761" style="zoom:50%;" />

物理集群：每台服务器有 8 个 V100 GPU (32GiB)、24 个 CPU 内核、500 GB DRAM 和 SSD 存储。

仿真集群：

* 跨 16 台服务器的 128 GPU 集群；
* 跨 64 台机器的 512 GPU 集群；



### 物理集群：资源敏感调度对物理集群目标的提升

两个实验：

* 实验一：100 个作业的静态生产衍生跟踪，拆分 (60,30,10)，使用 FIFO 安排并评估 $makespan$。
* 实验二：具有连续作业到达和 (30,60,10) 分割的动态生产跟踪，使用 SRTF 计划并评估平均和第 99 个百分位 JCT。

<img src="https://s3.bmp.ovh/imgs/2022/11/05/e56fe6905b969eaf.png" alt="image-20221105192242231" style="zoom:50%;" />

比较了三种算法，同时在物理集群和128G的仿真集群进行测试。

这个实验证明两点：

* tune 算法的性能。【Synergy-TUNE 实现的集群目标在这种情况下的最优解的 4% 以内。】
* 仿真实验的保真度，所以接下来的实验可以在模拟器中进行。【真实集群和模拟集群中的指标差异小于 5%。】

### 仿真集群：资源敏感调度对仿真集群目标的提升

实验一：64 台服务器上的 512 个 GPU，(20,70,10) 的工作负载分配，比较了两个算法和三个调度策略。

实验二：测试了SRTF 策略的平均和第 99 个百分位 JCT。【小于4小时则视为短作业】

实验三：测试相对于 GPU 比例调度的单个作业加速。

![image-20221105193148330](https://s3.bmp.ovh/imgs/2022/11/05/14c315104fde625d.png)

实验分析：

* 实验一：在所有策略中，与 GPU 比例调度相比，Synergy 能够降低平均 JCT，因为作业之间的资源分配更好。Synergy 的收益可归因于将未充分利用的资源从作业重新分配到不同的、资源敏感的作业，其吞吐量可以随着分配的增加而提高。
* 实验二：Synergy 将短期工作的分布尾部减少了 2.2 倍，长期和短期工作的平均 JCT 减少了 15%。
* 实验三：相对于 GPU 比例调度的单个作业加速，我们看到 Synergy 使用更好的资源分配将作业速度提高了 9 倍。



实验四：16 台服务器上的 128 个 GPU，(20,70,10) 的工作负载分配，比较了作业在单GPU【一个GPU】和多GPU【最多需要16个GPU】情境下，tune算法和按比例分配算法在四个调度策略【FIFO、SRTF、LAS 和 FTF】的性能。

三个场景：

* 图 7 中的 LAS（多 GPU 跟踪）

  ![image-20221106102006166](https://s3.bmp.ovh/imgs/2022/11/06/bd82f3306ec64ce8.png)

  

* 图 8 中的 SRTF（多 GPU 跟踪）

  ![image-20221106102049427](https://s3.bmp.ovh/imgs/2022/11/06/b33554b4e0d8650d.png)

* 图 9 中的 FIFO（单 GPU 跟踪）

  <img src="https://s3.bmp.ovh/imgs/2022/11/06/fcce10f03c1079b8.png" alt="image-20221106102105477" style="zoom:50%;" />

实验分析：

* Synergy-TUNE 在单 GPU 跟踪中将平均 JCT 降低了 3.4 倍，在多 GPU 跟踪中降低了 1.6 倍，它通过加速分配不成比例的资源敏感作业。
  * 当加载的job越多，平均 JCT 的降低就越明显，这主要是因为当job越多，排队时延越长，由于 Synergy 使用不成比例的资源分配显着加快了单个作业的速度，从而加快了job的调度，减少排队时延。
* Synergy-TUNE 能够承受比 GPU 比例分配更大的集群负载。
* 使用 Synergy-TUNE 实现的平均 JCT 在所有情况下都在最优解的 10% 以内

### 5.4 Synergy-TUNE 和 Synergy-GREEDY 在不同工作负载拆分下的表现如何以及它们如何利用可用资源

实验：在不同工作负载拆分下，三种策略【按比例，贪心，tune】的性能。

![image-20221106104730821](https://s3.bmp.ovh/imgs/2022/11/06/ffa381f814c1884f.png)

实验分析：

* 整体来看，依旧是tune性能最好。
* 当资源敏感型job增加时【第一个和第三个比例增加】，贪心策略与按比例分配策略相比，显著的降低了性能。【这主要是贪心策略没有充分利用GPU资源】
* 而tune算法，在最坏的情况下【模型都需要大量消耗CPU和MEM资源】，至少保持了和按比例分配策略的性能。



#### 资源利用率：

实验一：在集群 GPU 需求高于 100% 的情况下，在 5.5 个作业/小时的负载下，（50，0，50）的工作负载拆分，随时间的 GPU 和 CPU 的资源利用率。

实验二：在低负载的情况下，测试了随时间的CPU资源利用率。

<img src="https://s3.bmp.ovh/imgs/2022/11/06/612a72e62237c23a.png" alt="image-20221106105851345" style="zoom:50%;" />

分析：

* 实验一：按比例策略和tune策略的GPU利用率差不多，但是贪心策略为了更高了CPU和MEM利用率从而低效利用GPU，导致GPU利用率下降。
* 实验二：按比例分配因为没有考虑负载的资源敏感性，从而导致很多CPU资源的浪费，所以其CPU资源利用率低于tune策略。



### 5.5 Synergy 在不同 CPU:GPU 比率上的表现如何

实验：之前都是考虑在CPU：GPU = 3 的情况下的按比例策略和tune策略进行比较。现在修改比例，测试在不同比例下，Synergy的表现。使用FIFO调度策略。

![image-20221106110541208](https://s3.bmp.ovh/imgs/2022/11/06/ceb24a02821c8e36.png)

实验分析：

* 随着比例的增加，按比例分配策略的每一个GPU可以获得更多的CPU资源，从而提高了一部分模型的训练速度。
* 但是总体而言，对于 3、4、5 和 6 的 CPU：GPU 比率，Synergy-TUNE 将平均 JCT 降低了 3.4 倍、3 倍、2.2 倍和 1.8 倍。

### 5.6 将 Synergy-TUNE 与 Synergy-OPT 进行比较

* 对于我们实验中使用的 128 个 GPU 的集群大小，Synergy-TUNE 收敛于最优值 10% 以内的分配，比 Synergy-OPT 快 200 倍。

### 5.7 将 Synergy 与大数据调度程序进行比较 

<img src="https://s3.bmp.ovh/imgs/2022/11/06/35e57bb14bd55e5e.png" alt="image-20221106114013951" style="zoom:50%;" />

结论：

对于工作负载拆分 W2，使用 Synergy 调整跨作业的资源分配将 DRF 的平均 JCT 降低了 7.2 倍，Tetris的 JCT 降低了 1.8 倍。

这是因为 Synergy 能够在每一轮以可替代的方式分配辅助资源，而大数据调度程序的静态分配执行类似于贪婪技术，导致 GPU 碎片化，从而降低整体集群指标。





## 相关工作

* DNN 集群调度程序：
  * DNN 工作负载调度程序都专注于改进某个目标：【用户固定GPU数量】
    * Gandiva：集群利用率
    * Tiresias：JCT
    * Themis、Gandiva-Fair：公平性
  * 为单个作业动态的选择资源：
    * Pollux、AFS：利用吞吐量指标在多租户集群中动态的选择资源
* 大数据调度程序：
  * Tetris：一个多资源集群调度程序，它根据所有资源类型【CPU、内存、磁盘和网络。】的要求将任务打包到机器上。
  * DRF：考虑在包含不同资源类型的系统中的公平资源分配问题，其中每个用户可能对每个资源有不同的需求，DRF将max-min公平性推广到多种资源类型。



## 总结反思

### 未来工作：

* 本文只研究了重新分配CPU和内存，将CPU密集型和非密集型放置在一个节点上，之后可以考虑扩展到存储和网络带宽的要求。比如：将网络带宽密集型和非密集型放置在同一个节点上。
* GPU共享：如果有数据停滞，即使高效利用GPU也没用，因为没有输入数据输入到GPU中，未来可以考虑探索如何在 GPU 空间共享的同时赋予资源敏感性意识。
* 在本文中，如果一台服务器上的GPU满足要求，则只能为作业分配不超过一台服务器的 CPU 或内存资源。虽然说多GPU工作被分割成多个部分可能会导致通信开销，但是可能多分配的CPU和内存资源获得的吞吐量的提升可以掩盖跨节点的通信开销。多GPU任务合并与分割之间的权衡也是一个值得研究的问题。





### 疑问：

* DNN cluster schedulers 和 Big data schedulers 的区别是什么？
* 调度机制中，tune算法，怎么为每个任务选择合适的CPU和MEM分配？如果是多GPU任务，怎么选择一组合适的节点？



### 总结：

提高DNN训练，之前很多工作的重心都是放在GPU上，本文主要是从CPU和内存入手，研究CPU和内存对不同工作负载的影响。实验发现，对于 image 和 speech 模型，增加CPU资源可以加速训练。本文从这个入手，设计了Synergy这个调度框架，该框架可以很好的识别不同负载对CPU和MEM的敏感程度，并给出一个具体的调度方案。Synergy 主要包含两个组成部分：

* 最优化分析：这个分析方法使用MinIO，通过建模预测不同内存的吞吐量，再通过二分进一步优化配置时间，从而达到快速的配置一个任务的资源敏感矩阵。
* 调度机制：Synergy 设计了 tune 调度算法，该算法的核心思想是：如果该任务在整个集群找不到合适的server来为其服务，首先会调整本身的CPU和内存资源；如果仍然找不到合适的，则会不断调整正在运行的任务的CPU和内存资源，直到找到合适的server为其服务。



















