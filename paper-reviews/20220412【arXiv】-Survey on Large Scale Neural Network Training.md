By AoDong Chen
# 大规模神经网络训练的研究调查
[Survey on Large Scale Neural Network Training](https://arxiv.org/pdf/2202.10435.pdf)


这项调查对如何使DNN训练更有效率的方法进行了系统性概述。作者分析了如何在单个或多个GPU的上节省内存并充分利用计算和通信资源。作者对这些技术和策略进行分类并比较了同一类别内和不同类别间的策略。此外，还对具体的可以用的实现进行了讨论。

## 论文作者
俄罗斯斯科尔科沃科学技术研究所、法国里尔大学、波尔多大学、Inria 等科研机构联合发表

## 单个GPU上的显存节约技术
主要有两种方式来减少显存占用：
- 重计算
- 卸载

### 中间结果的重计算
训练过程有前向传播和反向传播，反向传播的作用是计算梯度然后更新权重，在计算梯度的时候需要使用到前向转播的每一层的输出结果，因此一般情况下显存中需要保存所有层的中间结果。但是大模型如果保存所有结果会放不下，因此可以采取用时间换空间的方法：就是只保存模型中的某一些层的计算结果，反向传播计算梯度时需要的刚好时已经保存好的中间结果就直接计算，需要的是之前没有保存的就从某一个保存好的值开始部分的前向传播得到当前需要的值。这样时间长了但是节省了显存占用。那么这个方向遇到的问题就是在一个模型中应该挑选那些层的结果保存下来，可以使一次训练的时间最短。于是就有很多工作来解决这个问题，这些方法根据模型的结构类型分成三类：
- 同构线性网络（由相同的结构的子网络线性构成的模型）
  - 二项式方法在中被证明是最优的，并在REVOLVE中实现。
  - 基于编译器技术的通用分而治之方法可以对任意程序进行自动微分。然而它假设计算可以在任意点中断，使得它不适合于GPU计算。
- 异构线性网络（CNN，ResNet）
  - 在计算时间不同和内存占用相同的情况下，可以通过动态规划找到最佳策略
- 通用网络
  - 新的问题建模，使用动态规划求解找到最佳策略
  - 构建成线性规划问题，指数级时间复杂度
  - 启发式搜索，主要策略就是不保持大的、生命周期长的、容易重新计算的中间结果

### 中间结果的卸载（内存交换）
内存交换是一种技术，它通过在前向传递时将中间结果卸载到CPU内存，并将其预取回GPU内存用于相应的后向计算来节省GPU内存。由于CPU和GPU之间的PCI总线的带宽有限，必须解决选择传输哪些中间值和何时传输的问题。
- vDNN采用了一种对CNN有效的启发式方法，只卸载了卷积层的输入
- TFLMS考虑中间结果的生命周期来选择卸载的中间值，并使用图搜索方法来确定插入加载/重取操作的时刻
- 基于优先级的方法
- 遗传算法
- 启发式、动态规划

### 权重卸载
中间结果卸载的很多方法也可以直接用到权重卸载上。此外还有一下方法：
- 每次只加载一层的权重
- 每次加载部分权重
- 还有减少卸载后的通信开销的工作

## 单个GPU无法放下单个模型的并行方法
模型并行，就是单个放不下，把模型切成好几份放在不同的设备上，设备与设备间需要传输被分开的相邻层的数据，但是由于模型顺序执行，这样拆分设备要依赖于前一个设备，计算机设备会空闲。
- GPipe将每一个batch划分成更小的mini-batch，流水线处理的bubble就会更小，等所有mini-batch前向反向完了后再更新权重，资源利用率不高。
- PipeDream通过强制要求前向和后向任务对一个给定的小批次使用相同的模型权重保证模型的精度，（每一个流水线阶段算完直接更新权重）增加了资源利用率。
- Chimera中的流水线异步更新权重会严重影响收敛结果
- 不频繁的更新权重可以减缓梯度过期现象
- PipeMare在反向传播的时候根据流水线的阶段调整学习率和模型权重。该方法实现了与GPipe相同的收敛率，同时具有与PipeDream相同的资源利用率，不需要存储多份权重。

## 跨设备模型训练的优化器
### 减少数据冗余来降低内存占用
- 数据和模型并行都保持了整个训练过程中所需的所有模型状态，但并不是所有的时间都是必需的。例如，仅在某个层的正向传播和反向传播期间才需要与每个层对应的参数。因此，ZeRO通过对参数（包括优化器状态、梯度和参数）进行分区来消除这种内存冗余，每个GPU仅保存部分参数及相关状态。
- 然后将上面和CPU端权重卸载结合起来，在CPU端做梯度更新
- 后续工作使用更好的通信协议，尽量将计算和通信重叠起来

### 低精度的优化器
- 块状动态量化技术能够将优化器的状态保存成8bit格式但是效果和32bit的一样好
- 还有人提出用特殊的规则将优化器状态保存成4bit格式

### 加速收敛
#### 减少通信开销
在传输数据前可以进行数据压缩
- 稀疏化。只传输完整梯度元素的一部分也只更新一部分，这种方法既减少了通信开销也保证了模型精度。
- 先量化传输梯度，然后恢复或者提供补偿机制。
- 矩阵降秩（矩阵奇异值分解），奇异值分解耗时较大。

#### 增大batchsize
该方法可以减少迭代次数和增加GPU利用率
- 使用线性缩放规则来根据批量大小调整学习率，这可以使收敛不受影响
- Adam等考虑到每一层的参数和梯度差距巨大，设计了一种考虑层的学习率调整方法。


## 结论
重计算领域中寻找合适的中间结果保存点的方法还不够通用；将该方法与内存交换和流水线技术结合起来是一个不错的研究方向；关于使用低精度的优化器来解决大模型训练的问题的方法还不是很鲁棒，比如低精度需要专用的运算单元；对于一些数据近似的方法应该给予关注，因为他们减少开销的同时有可以接收的精度损失；最有前途的就是开发新的计算架构和更底层的优化技术。
